{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4438f3-aa69-47d8-ae7b-aac5f0c432c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/shephalidubey/.local/lib/python3.10/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/ai_dev/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9753a889-264c-42e2-9623-25821e2b3d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded OpenAI API Key: sk-Etun-u-I43DEKOuViX9F-y-kjpPSJNgx5myeLEYKE2T3BlbkFJrLV8Z0os3xZqsaAh9x7E9AxVi-5DC_gw1r8wGxMK4A\n",
      "Text length: 11602\n",
      "Text snippet: AQI DETECTIVES /g34B  \n",
      "\u0000  /g34B  /g34B  /g34B  /g294\n",
      "Air Quality: A Critical Global Concern\n",
      "Collaborators: Shephali Dubey/Girish Hosalli/Christine Chung/Chearine \n",
      "Pringle/Xiwu Dai\n",
      "Project Overview & Goals\n",
      "Air quality is a vital aspect of our environment and human health. The \n",
      "quality of the air we breathe directly impacts our well-being and the \n",
      "sustainability of our planet. Our project aims to discover trends in air \n",
      "pollution in New York City and Long Island and do a deep dive into the air \n",
      "qu\n",
      "Summary:\n",
      "The text discusses a project focused on analyzing air quality trends in New York City and Long Island over the past 12 years using Machine Learning models to predict the Air Quality Index (AQI) for the next year. The project aims to help individuals, especially sensitive groups, make informed decisions about outdoor activities and assist governments in managing traffic patterns and industrial emissions to reduce Climate Change. The project involves data collection, model development using Supervised Learning ML Models, forecasting with Random Forest and Prophet Models, and analyzing temporal and spatial trends in air quality. Key observations include seasonal patterns, pollutant-specific variations, and the distribution of AQI scores.\n",
      "The text discusses the distribution of AQI scores across counties and time periods, including factors such as central tendency, spread, skewness, and multiple peaks. It highlights observations such as the impact of Canadian wildfires on air quality, winter inversions, summer ozone events, and the urban heat island effect. The text also compares regression models for predicting AQI trends and outlines the project's current and future approach, including setbacks and potential enhancements. The conclusion emphasizes the project's achievements in leveraging historical air quality data and using advanced machine learning models to predict future trends in New York City and Long Island.\n",
      "The text discusses the importance of monitoring and improving air quality, highlighting key pollutants and their health and environmental impacts. It also mentions factors impacting air quality, such as wind patterns and human activities, and provides recommendations for public health, policy, further research, and monitoring. The text emphasizes the need for collective efforts to adopt sustainable practices and invest in clean technologies to create a healthier and more sustainable future.\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('/users/shephalidubey/Documents/keys.env')\n",
    "\n",
    "# Set your OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "# print(f\"Loaded OpenAI API Key: {OPENAI_API_KEY}\")  # Debug line\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"  # Handle potential None values\n",
    "    return text\n",
    "\n",
    "def summarize_text(text):\n",
    "    max_input_length = 4096  # Adjust if necessary\n",
    "    text_chunks = [text[i:i + max_input_length] for i in range(0, len(text), max_input_length)]\n",
    "\n",
    "    summaries = []\n",
    "    chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "    for chunk in text_chunks:\n",
    "        # Create a message object\n",
    "        message = HumanMessage(content=f\"Summarize the following text:\\n\\n{chunk}\")\n",
    "        \n",
    "        response = chat_model([message])\n",
    "        summary = response.content  # Correct access to summary content\n",
    "        summaries.append(summary)\n",
    "\n",
    "    return \"\\n\".join(summaries)  # Join summaries with newlines for readability\n",
    "\n",
    "def main(pdf_path):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        print(\"No text found in PDF.\")\n",
    "        return\n",
    "    print(f\"Text length: {len(text)}\")\n",
    "    print(f\"Text snippet: {text[:500]}\")  # Print the first 500 characters\n",
    "\n",
    "    summary = summarize_text(text)   \n",
    "    print(\"Summary:\")\n",
    "    print(summary)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"/users/shephalidubey/Documents/AQI-DETECTIVES.pdf\"  # Replace with your PDF file path\n",
    "    main(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93376f-5c44-4206-bb23-a07275b2efa6",
   "metadata": {},
   "source": [
    "Explanation\n",
    "extract_text_from_pdf: This function reads the PDF and extracts text from each page.\n",
    "summarize_text: This function uses a pre-trained summarization model from Hugging Face to generate a summary. Adjust the max_length and min_length parameters to fit your summarization needs.\n",
    "main: This function ties everything together. It extracts text from the PDF, summarizes it, and prints the summary.\n",
    "Running the Code\n",
    "Save the code to a file, e.g., pdf_summarizer.py.\n",
    "Replace \"example.pdf\" with the path to your PDF file.\n",
    "Run the script: python pdf_summarizer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4affcbe1-fa27-4478-8ec1-8287b3ac962d",
   "metadata": {},
   "source": [
    "For summarizing very large texts, especially when working with PDFs, consider the following models and pipelines that are known for handling long documents effectively:\n",
    "\n",
    "1. Longformer\n",
    "Model: allenai/longformer-large-4096\n",
    "Description: Longformer is specifically designed to handle long documents by using a sparse attention mechanism. This allows it to process longer sequences than traditional transformers.facebook/bart-large-LED, which is a Longformer variant specifically designed for summarization tasks.\n",
    "Simplified Pipeline: The summarization is handled more directly without needing to deal with tokenizers separately.\n",
    "2. BigBird\n",
    "Model: google/bigbird-roberta-base\n",
    "Description: Similar to Longformer, BigBird can handle long sequences efficiently. It employs a combination of global and local attention, making it suitable for long texts.\n",
    "3. LED (Longformer Encoder-Decoder)\n",
    "Model: facebook/bart-large-LED\n",
    "Description: This model is built on Longformer and is designed for sequence-to-sequence tasks, like summarization, while supporting longer inputs.OSError: facebook/bart-large-LED is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
    "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
    "4. GPT-3 or GPT-4 (if accessible)\n",
    "Description: If you have access to OpenAI’s API for GPT models, they can generate summaries for large texts effectively. You might need to break your text into smaller parts, but they handle context well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267214ba-6d2f-40d1-ab75-f72c365add13",
   "metadata": {},
   "source": [
    "Additional Considerations\n",
    "Chunking: If the text is extremely long, you may still need to chunk it, as even these models have maximum input sizes.\n",
    "Preprocessing: Ensure the text extracted from the PDF is clean and properly formatted before summarization to improve the quality of the output.\n",
    "Performance: Keep an eye on performance and response time, especially with larger models, as they may require more resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ff3535-00a7-4016-8aeb-d3e3e4bd2988",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30564d93-5fc7-43e7-9fd9-923dd033599a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
